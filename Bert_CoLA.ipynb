{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Bert_Final",
      "provenance": [],
      "private_outputs": true,
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "4dq4NkRu_u3i",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install transformers catalyst"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XlHnoGZN6OKy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "import random\n",
        "import sys\n",
        "import urllib.request\n",
        "import zipfile\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from tqdm import tqdm, trange\n",
        "\n",
        "import torch\n",
        "from torch import nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import DataLoader, RandomSampler, Dataset, SequentialSampler\n",
        "from torch.utils.data import TensorDataset, random_split\n",
        "\n",
        "import transformers\n",
        "from transformers import BertTokenizer\n",
        "from transformers import BertTokenizer, BertForPreTraining\n",
        "from transformers import BertForSequenceClassification, AdamW, BertConfig\n",
        "from transformers import get_linear_schedule_with_warmup\n",
        "from transformers import glue_processors as processors\n",
        "\n",
        "from catalyst.dl import SupervisedRunner\n",
        "from catalyst.dl.callbacks import AccuracyCallback, SchedulerCallback, F1ScoreCallback\n",
        "from catalyst.utils import set_global_seed, prepare_cudnn"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "4H6_6zgnfRQR",
        "colab": {}
      },
      "source": [
        "TASKS = [\"CoLA\", \"SST\", \"MRPC\", \"QQP\", \"STS\", \"MNLI\", \"SNLI\", \"QNLI\", \"RTE\", \"WNLI\"]\n",
        "TASK2PATH = {\n",
        "    \"CoLA\": \"https://firebasestorage.googleapis.com/v0/b/mtl-sentence-representations.appspot.com/o/data%2FCoLA.zip?alt=media&token=46d5e637-3411-4188-bc44-5809b5bfb5f4\",\n",
        "    \"SST\": \"https://firebasestorage.googleapis.com/v0/b/mtl-sentence-representations.appspot.com/o/data%2FSST-2.zip?alt=media&token=aabc5f6b-e466-44a2-b9b4-cf6337f84ac8\",\n",
        "    \"MRPC\": \"https://firebasestorage.googleapis.com/v0/b/mtl-sentence-representations.appspot.com/o/data%2Fmrpc_dev_ids.tsv?alt=media&token=ec5c0836-31d5-48f4-b431-7480817f1adc\",\n",
        "    \"QQP\": \"https://firebasestorage.googleapis.com/v0/b/mtl-sentence-representations.appspot.com/o/data%2FQQP.zip?alt=media&token=700c6acf-160d-4d89-81d1-de4191d02cb5\",\n",
        "    \"STS\": \"https://firebasestorage.googleapis.com/v0/b/mtl-sentence-representations.appspot.com/o/data%2FSTS-B.zip?alt=media&token=bddb94a7-8706-4e0d-a694-1109e12273b5\",\n",
        "    \"MNLI\": \"https://firebasestorage.googleapis.com/v0/b/mtl-sentence-representations.appspot.com/o/data%2FMNLI.zip?alt=media&token=50329ea1-e339-40e2-809c-10c40afff3ce\",\n",
        "    \"SNLI\": \"https://firebasestorage.googleapis.com/v0/b/mtl-sentence-representations.appspot.com/o/data%2FSNLI.zip?alt=media&token=4afcfbb2-ff0c-4b2d-a09a-dbf07926f4df\",\n",
        "    \"QNLI\": \"https://firebasestorage.googleapis.com/v0/b/mtl-sentence-representations.appspot.com/o/data%2FQNLIv2.zip?alt=media&token=6fdcf570-0fc5-4631-8456-9505272d1601\",\n",
        "    \"RTE\": \"https://firebasestorage.googleapis.com/v0/b/mtl-sentence-representations.appspot.com/o/data%2FRTE.zip?alt=media&token=5efa7e85-a0bb-4f19-8ea2-9e1840f077fb\",\n",
        "    \"WNLI\": \"https://firebasestorage.googleapis.com/v0/b/mtl-sentence-representations.appspot.com/o/data%2FWNLI.zip?alt=media&token=068ad0a0-ded7-4bd7-99a5-5e00222e0faf\",\n",
        "}\n",
        "\n",
        "MRPC_TRAIN = \"https://dl.fbaipublicfiles.com/senteval/senteval_data/msr_paraphrase_train.txt\"\n",
        "MRPC_TEST = \"https://dl.fbaipublicfiles.com/senteval/senteval_data/msr_paraphrase_test.txt\"\n",
        "\n",
        "data_dir = \"data/\"\n",
        "max_seq_length = 128"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4O8Y-go7czun",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def download_and_extract(task, data_dir):\n",
        "    print(\"Downloading and extracting %s...\" % task)\n",
        "    data_file = \"%s.zip\" % task\n",
        "    urllib.request.urlretrieve(TASK2PATH[task], data_file)\n",
        "    with zipfile.ZipFile(data_file) as zip_ref:\n",
        "        zip_ref.extractall(data_dir)\n",
        "    os.remove(data_file)\n",
        "    print(\"\\tCompleted!\")\n",
        "\n",
        "def format_mrpc(data_dir, path_to_data):\n",
        "    print(\"Processing MRPC...\")\n",
        "    mrpc_dir = os.path.join(data_dir, \"MRPC\")\n",
        "    if not os.path.isdir(mrpc_dir):\n",
        "        os.mkdir(mrpc_dir)\n",
        "    if path_to_data:\n",
        "        mrpc_train_file = os.path.join(path_to_data, \"msr_paraphrase_train.txt\")\n",
        "        mrpc_test_file = os.path.join(path_to_data, \"msr_paraphrase_test.txt\")\n",
        "    else:\n",
        "        print(\"Local MRPC data not specified, downloading data from %s\" % MRPC_TRAIN)\n",
        "        mrpc_train_file = os.path.join(mrpc_dir, \"msr_paraphrase_train.txt\")\n",
        "        mrpc_test_file = os.path.join(mrpc_dir, \"msr_paraphrase_test.txt\")\n",
        "        urllib.request.urlretrieve(MRPC_TRAIN, mrpc_train_file)\n",
        "        urllib.request.urlretrieve(MRPC_TEST, mrpc_test_file)\n",
        "    assert os.path.isfile(mrpc_train_file), \"Train data not found at %s\" % mrpc_train_file\n",
        "    assert os.path.isfile(mrpc_test_file), \"Test data not found at %s\" % mrpc_test_file\n",
        "    urllib.request.urlretrieve(TASK2PATH[\"MRPC\"], os.path.join(mrpc_dir, \"dev_ids.tsv\"))\n",
        "\n",
        "    dev_ids = []\n",
        "    with open(os.path.join(mrpc_dir, \"dev_ids.tsv\"), encoding=\"utf8\") as ids_fh:\n",
        "        for row in ids_fh:\n",
        "            dev_ids.append(row.strip().split(\"\\t\"))\n",
        "\n",
        "    with open(mrpc_train_file, encoding=\"utf8\") as data_fh, open(\n",
        "        os.path.join(mrpc_dir, \"train.tsv\"), \"w\", encoding=\"utf8\"\n",
        "    ) as train_fh, open(os.path.join(mrpc_dir, \"dev.tsv\"), \"w\", encoding=\"utf8\") as dev_fh:\n",
        "        header = data_fh.readline()\n",
        "        train_fh.write(header)\n",
        "        dev_fh.write(header)\n",
        "        for row in data_fh:\n",
        "            label, id1, id2, s1, s2 = row.strip().split(\"\\t\")\n",
        "            if [id1, id2] in dev_ids:\n",
        "                dev_fh.write(\"%s\\t%s\\t%s\\t%s\\t%s\\n\" % (label, id1, id2, s1, s2))\n",
        "            else:\n",
        "                train_fh.write(\"%s\\t%s\\t%s\\t%s\\t%s\\n\" % (label, id1, id2, s1, s2))\n",
        "\n",
        "    with open(mrpc_test_file, encoding=\"utf8\") as data_fh, open(\n",
        "        os.path.join(mrpc_dir, \"test.tsv\"), \"w\", encoding=\"utf8\"\n",
        "    ) as test_fh:\n",
        "        header = data_fh.readline()\n",
        "        test_fh.write(\"index\\t#1 ID\\t#2 ID\\t#1 String\\t#2 String\\n\")\n",
        "        for idx, row in enumerate(data_fh):\n",
        "            label, id1, id2, s1, s2 = row.strip().split(\"\\t\")\n",
        "            test_fh.write(\"%d\\t%s\\t%s\\t%s\\t%s\\n\" % (idx, id1, id2, s1, s2))\n",
        "    print(\"\\tCompleted!\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M4hNWuZ5okuj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "TASKS = [\"CoLA\", \"SST\"] # Или можно просто сюда вписать те датасеты, которые ты выбрал.\n",
        "\n",
        "for task in TASKS:\n",
        "    if task == \"MRPC\":\n",
        "        format_mrpc(data_dir, None)\n",
        "    else:\n",
        "        download_and_extract(task, data_dir)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZThKxLcKts2g",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Load the BERT tokenizer.\n",
        "print('Loading BERT tokenizer...')\n",
        "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased', do_lower_case=True)\n",
        "print('Tokenizer loaded')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8B7oC7kClPdc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Prepare_Dataset():\n",
        "    def __init__(self, tokenizer, dataset_name, test):\n",
        "        self.tokenizer = tokenizer\n",
        "        self.dataset_name = dataset_name\n",
        "        self.test = test\n",
        "        self.loaded_data = self.load_data()\n",
        "        \n",
        "    def load_data(self):\n",
        "\n",
        "        # Load data from tsv files\n",
        "        if self.test:\n",
        "            self.df = pd.read_csv('./data/{0}/dev.tsv'.format(self.dataset_name), delimiter='\\t', names=['sentence_source', 'label', 'label_notes', 'sentence'])\n",
        "            print(self.df.head())\n",
        "        else:\n",
        "            self.df = pd.read_csv('./data/{0}/train.tsv'.format(self.dataset_name), delimiter='\\t', names=['sentence_source', 'label', 'label_notes', 'sentence'])\n",
        "            print(self.df.head())\n",
        "        # Get the lists of sentences and their labels.\n",
        "        self.sentences = self.df.sentence.values\n",
        "        self.labels = self.df.label.values\n",
        "\n",
        "    def tokenize_data(self):\n",
        "\n",
        "    \n",
        "\n",
        "        # Tokenize all of the sentences and map the tokens to thier word IDs.\n",
        "        input_ids = []\n",
        "        attention_masks = []\n",
        "\n",
        "        # For every sentence...\n",
        "        for sent in self.sentences:\n",
        "\n",
        "            \n",
        "\n",
        "            # `encode_plus` will:\n",
        "            #   (1) Tokenize the sentence.\n",
        "            #   (2) Prepend the `[CLS]` token to the start.\n",
        "            #   (3) Append the `[SEP]` token to the end.\n",
        "            #   (4) Map tokens to their IDs.\n",
        "            #   (5) Pad or truncate the sentence to `max_length`\n",
        "            #   (6) Create attention masks for [PAD] tokens.\n",
        "            encoded_dict = tokenizer.encode_plus(\n",
        "                                sent,                      # Sentence to encode.\n",
        "                                add_special_tokens = True, # Add '[CLS]' and '[SEP]'\n",
        "                                max_length = max_seq_length,           # Pad & truncate all sentences.\n",
        "                                pad_to_max_length = True,\n",
        "                                return_attention_mask = True,   # Construct attn. masks.\n",
        "                                return_tensors = 'pt',     # Return pytorch tensors.\n",
        "                          )\n",
        "            \n",
        "            \n",
        "\n",
        "            # Add the encoded sentence to the list.    \n",
        "            input_ids.append(encoded_dict['input_ids'])\n",
        "            \n",
        "            # And its attention mask (simply differentiates padding from non-padding).\n",
        "            attention_masks.append(encoded_dict['attention_mask'])\n",
        "\n",
        "        # Convert the lists into tensors.\n",
        "        input_ids = torch.cat(input_ids, dim=0)\n",
        "        attention_masks = torch.cat(attention_masks, dim=0)\n",
        "        labels = torch.tensor(self.labels)\n",
        "\n",
        "        # Print sentence 0, now as a list of IDs.\n",
        "        print('Original: ', self.sentences[0])\n",
        "        print('Token IDs:', input_ids[0])\n",
        "\n",
        "        return input_ids, attention_masks, labels, self.df"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XXub4cDRqggE",
        "colab_type": "text"
      },
      "source": [
        "### Create TensorDataset and split it\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3xUcYedQqbji",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Load train data\n",
        "loadTrainData = Prepare_Dataset(tokenizer=tokenizer, dataset_name='CoLA', test=False)\n",
        "\n",
        "input_ids_train, attention_masks_train, labels_train, train_df = loadTrainData.tokenize_data()\n",
        "\n",
        "# Combine the training inputs into a TensorDataset.\n",
        "dataset_train = TensorDataset(input_ids_train, attention_masks_train, labels_train)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yxD13UA1tz9U",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Create a 90-10 train-validation split.\n",
        "\n",
        "# Calculate the number of samples to include in each set.\n",
        "train_size = int(0.9 * len(dataset_train))\n",
        "val_size = len(dataset_train) - train_size\n",
        "\n",
        "# Divide the dataset by randomly selecting samples.\n",
        "train_dataset_train, val_dataset_train = random_split(dataset_train, [train_size, val_size])\n",
        "\n",
        "print('{:>5,} training samples'.format(train_size))\n",
        "print('{:>5,} validation samples'.format(val_size))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0VhLvR0dCTzy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Load Test data\n",
        "\n",
        "loadTestData = Prepare_Dataset(tokenizer=tokenizer, dataset_name='CoLA', test=True)\n",
        "\n",
        "input_ids_test, attention_masks_test, labels_test, test_df = loadTestData.tokenize_data()\n",
        "\n",
        "# Combine the training inputs into a TensorDataset.\n",
        "dataset_test = TensorDataset(input_ids_test, attention_masks_test, labels_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h-dr--H-C6st",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print('{:>5,} test samples'.format(len(dataset_test)))\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nwSehprQxv4r",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# The DataLoader needs to know our batch size for training, so we specify it \n",
        "# here. For fine-tuning BERT on a specific task, the authors recommend a batch \n",
        "# size of 16 or 32.\n",
        "batch_size = 32\n",
        "\n",
        "# Create the DataLoaders for our training and validation sets.\n",
        "# For train\n",
        "train_dataloader = DataLoader(\n",
        "            train_dataset_train,  # The training samples.\n",
        "            sampler = RandomSampler(train_dataset_train), # Select batches randomly\n",
        "            batch_size = batch_size # Trains with this batch size.\n",
        "        )\n",
        "\n",
        "# For validation\n",
        "validation_dataloader = DataLoader(\n",
        "            val_dataset_train, # The validation samples.\n",
        "            sampler = SequentialSampler(val_dataset_train), # Pull out batches sequentially.\n",
        "            batch_size = batch_size # Evaluate with this batch size.\n",
        "        )"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HcmzUK63DP1K",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# For test\n",
        "batch_size = 32\n",
        "\n",
        "test_dataloader = DataLoader(\n",
        "            dataset_test, # The validation samples.\n",
        "            sampler = SequentialSampler(dataset_test), # Pull out batches sequentially.\n",
        "            batch_size = batch_size # Evaluate with this batch size.\n",
        "        )"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8PO0XEAkKLK7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from transformers import BertForSequenceClassification"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7-22wBwrFMob",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = BertForSequenceClassification.from_pretrained(\n",
        "    \"bert-base-uncased\", # Use the 12-layer BERT model, with an uncased vocab.\n",
        "    num_labels = 2, # The number of output labels--2 for binary classification.\n",
        "                    # You can increase this for multi-class tasks.   \n",
        "    output_attentions = False, # Whether the model returns attentions weights.\n",
        "    output_hidden_states = False, # Whether the model returns all hidden-states.\n",
        ")\n",
        "\n",
        "# Tell pytorch to run this model on the GPU.\n",
        "model.cuda()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WyJrAwDrTjhA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "device"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8VsyoAmwjnb2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "seed = 404\n",
        "set_global_seed(seed)\n",
        "prepare_cudnn(True)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xA_GvD_y2PLA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "epochs = 2\n",
        "lr = 2e-5\n",
        "warmup_steps = len(train_dataloader) // 2\n",
        "\n",
        "optimizer_grouped_parameters = [\n",
        "    {\"params\": [p for n, p in model.named_parameters()], \"weight_decay\": 0.0},\n",
        "]\n",
        "optimizer = transformers.AdamW(optimizer_grouped_parameters, lr=lr)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ESP658bc2GUk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Create the learning rate scheduler.\n",
        "scheduler = get_linear_schedule_with_warmup(optimizer, \n",
        "                                            num_warmup_steps = 0, # Default value in run_glue.py\n",
        "                                            num_training_steps = warmup_steps)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tlLxE3RI3Ccc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import time\n",
        "import datetime\n",
        "\n",
        "def format_time(elapsed):\n",
        "    '''\n",
        "    Takes a time in seconds and returns a string hh:mm:ss\n",
        "    '''\n",
        "    # Round to the nearest second.\n",
        "    elapsed_rounded = int(round((elapsed)))\n",
        "    \n",
        "    # Format as hh:mm:ss\n",
        "    return str(datetime.timedelta(seconds=elapsed_rounded))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WOCJgoZR3Hh6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "# Function to calculate the accuracy of our predictions vs labels\n",
        "def flat_accuracy(preds, labels):\n",
        "    pred_flat = np.argmax(preds, axis=1).flatten()\n",
        "    labels_flat = labels.flatten()\n",
        "    return np.sum(pred_flat == labels_flat) / len(labels_flat)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3WKeuits2dZ8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "training_stats = []\n",
        "\n",
        "# Measure the total training time for the whole run.\n",
        "total_t0 = time.time()\n",
        "\n",
        "# For each epoch...\n",
        "for epoch_i in range(0, epochs):\n",
        "    \n",
        "    # ========================================\n",
        "    #               Training\n",
        "    # ========================================\n",
        "    \n",
        "    # Perform one full pass over the training set.\n",
        "\n",
        "    print(\"\")\n",
        "    print('======== Epoch {:} / {:} ========'.format(epoch_i + 1, epochs))\n",
        "    print('Training...')\n",
        "\n",
        "    # Measure how long the training epoch takes.\n",
        "    t0 = time.time()\n",
        "\n",
        "    # Reset the total loss for this epoch.\n",
        "    total_train_loss = 0\n",
        "\n",
        "    # Put the model into training mode\n",
        "    model.train()\n",
        "\n",
        "    # For each batch of training data...\n",
        "    for step, batch in enumerate(train_dataloader):\n",
        "\n",
        "        # Progress update every 40 batches.\n",
        "        if step % 40 == 0 and not step == 0:\n",
        "            # Calculate elapsed time in minutes.\n",
        "            elapsed = format_time(time.time() - t0)\n",
        "            \n",
        "            # Report progress.\n",
        "            print('  Batch {:>5,}  of  {:>5,}.    Elapsed: {:}.'.format(step, len(train_dataloader), elapsed))\n",
        "\n",
        "        # Unpack this training batch from our dataloader. \n",
        "        # batch contains three pytorch tensors:\n",
        "        #   [0]: input ids \n",
        "        #   [1]: attention masks\n",
        "        #   [2]: labels \n",
        "        b_input_ids = batch[0].to(device)\n",
        "        b_input_mask = batch[1].to(device)\n",
        "        b_labels = batch[2].to(device)\n",
        "\n",
        "        \n",
        "        \n",
        "        model.zero_grad()        \n",
        "\n",
        "        \n",
        "        loss, logits = model(input_ids=b_input_ids, token_type_ids=None, attention_mask=b_input_mask, labels=b_labels)\n",
        "\n",
        "        # Accumulate the training loss over all of the batches\n",
        "        total_train_loss += loss.item()\n",
        "\n",
        "        # Perform a backward pass to calculate the gradients.\n",
        "        loss.backward()\n",
        "\n",
        "        # Clip the norm of the gradients to 1.0.\n",
        "        # This is to help prevent the \"exploding gradients\" problem.\n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
        "\n",
        "        # Update parameters and take a step using the computed gradient.\n",
        "        # The optimizer dictates the \"update rule\"--how the parameters are\n",
        "        # modified based on their gradients, the learning rate, etc.\n",
        "        optimizer.step()\n",
        "\n",
        "        # Update the learning rate.\n",
        "        scheduler.step()\n",
        "\n",
        "    # Calculate the average loss over all of the batches.\n",
        "    avg_train_loss = total_train_loss / len(train_dataloader)            \n",
        "    \n",
        "    # Measure how long this epoch took.\n",
        "    training_time = format_time(time.time() - t0)\n",
        "\n",
        "    print(\"\")\n",
        "    print(\"  Average training loss: {0:.2f}\".format(avg_train_loss))\n",
        "    print(\"  Training epcoh took: {:}\".format(training_time))\n",
        "        \n",
        "    # ========================================\n",
        "    #               Validation\n",
        "    # ========================================\n",
        "    # After the completion of each training epoch, measure our performance on\n",
        "    # our validation set.\n",
        "\n",
        "    print(\"\")\n",
        "    print(\"Running Validation...\")\n",
        "\n",
        "    t0 = time.time()\n",
        "\n",
        "    # Put the model in evaluation mode--the dropout layers behave differently\n",
        "    # during evaluation.\n",
        "    model.eval()\n",
        "\n",
        "    # Tracking variables \n",
        "    total_eval_accuracy = 0\n",
        "    total_eval_loss = 0\n",
        "    nb_eval_steps = 0\n",
        "\n",
        "    # Evaluate data for one epoch\n",
        "    for batch in validation_dataloader:\n",
        "        \n",
        "        \n",
        "        # batch contains three pytorch tensors:\n",
        "        #   [0]: input ids \n",
        "        #   [1]: attention masks\n",
        "        #   [2]: labels \n",
        "        b_input_ids = batch[0].to(device)\n",
        "        b_input_mask = batch[1].to(device)\n",
        "        b_labels = batch[2].to(device)\n",
        "        \n",
        "        # \n",
        "        with torch.no_grad():        \n",
        "\n",
        "            (loss, logits) = model(b_input_ids, \n",
        "                                   token_type_ids=None, \n",
        "                                   attention_mask=b_input_mask,\n",
        "                                   labels=b_labels)\n",
        "            \n",
        "        # Accumulate the validation loss.\n",
        "        total_eval_loss += loss.item()\n",
        "\n",
        "        # Move logits and labels to CPU\n",
        "        logits = logits.detach().cpu().numpy()\n",
        "        label_ids = b_labels.to('cpu').numpy()\n",
        "\n",
        "        # Calculate the accuracy for this batch of test sentences, and\n",
        "        # accumulate it over all batches.\n",
        "        total_eval_accuracy += flat_accuracy(logits, label_ids)\n",
        "        \n",
        "\n",
        "    # Report the final accuracy for this validation run.\n",
        "    avg_val_accuracy = total_eval_accuracy / len(validation_dataloader)\n",
        "    print(\"  Accuracy: {0:.2f}\".format(avg_val_accuracy))\n",
        "\n",
        "    # Calculate the average loss over all of the batches.\n",
        "    avg_val_loss = total_eval_loss / len(validation_dataloader)\n",
        "    \n",
        "    # Measure how long the validation run took.\n",
        "    validation_time = format_time(time.time() - t0)\n",
        "    \n",
        "    print(\"  Validation Loss: {0:.2f}\".format(avg_val_loss))\n",
        "    print(\"  Validation took: {:}\".format(validation_time))\n",
        "\n",
        "    # Record all statistics from this epoch.\n",
        "    training_stats.append(\n",
        "        {\n",
        "            'epoch': epoch_i + 1,\n",
        "            'Training Loss': avg_train_loss,\n",
        "            'Valid. Loss': avg_val_loss,\n",
        "            'Valid. Accur.': avg_val_accuracy,\n",
        "            'Training Time': training_time,\n",
        "            'Validation Time': validation_time\n",
        "        }\n",
        "    )\n",
        "\n",
        "print(\"\")\n",
        "print(\"Training complete!\")\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V8bjeySRXpKK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "\n",
        "# Saving best-practices: if you use defaults names for the model, you can reload it using from_pretrained()\n",
        "\n",
        "output_dir = '/content/drive/My Drive/Stepik_Mipt/BertModel/'\n",
        "\n",
        "# Create output directory if needed\n",
        "if not os.path.exists(output_dir):\n",
        "    os.makedirs(output_dir)\n",
        "\n",
        "print(\"Saving model to %s\" % output_dir)\n",
        "\n",
        "# Save a trained model, configuration and tokenizer using `save_pretrained()`.\n",
        "# They can then be reloaded using `from_pretrained()`\n",
        "model_to_save = model.module if hasattr(model, 'module') else model  # Take care of distributed/parallel training\n",
        "model_to_save.save_pretrained(output_dir)\n",
        "tokenizer.save_pretrained(output_dir)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rV0g56grXsoj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KuDy4BECAbG7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "output_dir = '/content/drive/My Drive/Stepik_Mipt/BertModel/'\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# Load a trained model and vocabulary \n",
        "model = BertForSequenceClassification.from_pretrained(output_dir)\n",
        "tokenizer = BertTokenizer.from_pretrained(output_dir)\n",
        "\n",
        "# Copy the model to the GPU.\n",
        "model.to(device)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fNLAw8p_EQOh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def test_predict(model, prediction_dataloader):\n",
        "    # Put model in evaluation mode\n",
        "    model.eval()\n",
        "\n",
        "    # Tracking variables \n",
        "    predictions , true_labels = [], []\n",
        "\n",
        "    # Predict \n",
        "    for batch in prediction_dataloader:\n",
        "        # Add batch to GPU\n",
        "        batch = tuple(t.to(device) for t in batch)\n",
        "        \n",
        "        # Unpack the inputs from our dataloader\n",
        "        b_input_ids, b_input_mask, b_labels = batch\n",
        "        \n",
        "        # Telling the model not to compute or store gradients, saving memory and \n",
        "        # speeding up prediction\n",
        "        with torch.no_grad():\n",
        "            # Forward pass, calculate logit predictions\n",
        "            outputs = model(b_input_ids, token_type_ids=None, \n",
        "                            attention_mask=b_input_mask)\n",
        "\n",
        "        logits = outputs[0]\n",
        "\n",
        "        # Move logits and labels to CPU\n",
        "        logits = logits.detach().cpu().numpy()\n",
        "        label_ids = b_labels.to('cpu').numpy()\n",
        "        \n",
        "        # Store predictions and true labels\n",
        "        predictions.append(logits)\n",
        "        true_labels.append(label_ids)\n",
        "\n",
        "    print('    DONE.')\n",
        "    return predictions, true_labels\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "znnliAWQE4uB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "pred, true = test_predict(model, test_dataloader)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s8qFoLRFGOQf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.metrics import matthews_corrcoef\n",
        "\n",
        "# Combine the results across all batches. \n",
        "predictions = np.concatenate(pred, axis=0)\n",
        "\n",
        "# For each sample, pick the label (0 or 1) with the higher score.\n",
        "predictions = np.argmax(predictions, axis=1).flatten()\n",
        "\n",
        "# Combine the correct labels for each batch into a single list.\n",
        "true_labels = np.concatenate(true, axis=0)\n",
        "\n",
        "# Calculate the MCC\n",
        "mcc = matthews_corrcoef(true_labels, predictions)\n",
        "\n",
        "print('Total MCC: %.3f' % mcc)"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}